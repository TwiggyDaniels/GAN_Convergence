{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import keras.backend as backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, \\\n",
    "    Input, Reshape\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the images being used\n",
    "IMG_ROWS = 104\n",
    "IMG_COL = 88\n",
    "IMG_CHANNELS = 1\n",
    "IMG_SHAPE = (IMG_ROWS, IMG_COL, IMG_CHANNELS)\n",
    "\n",
    "# image format\n",
    "IMG_EXT = '.png'\n",
    "# training data location\n",
    "DATA_DIR = 'img_align_celeba/'\n",
    "\n",
    "# image output directory\n",
    "IMAGE_DIR = 'images/'\n",
    "# loss graph output directory\n",
    "LOSS_DIR = 'loss/'\n",
    "# saved models directory\n",
    "MODEL_DIR = 'saved_models/'\n",
    "\n",
    "# make the directories if it doesn't exist\n",
    "try:\n",
    "    os.mkdir(IMAGE_DIR)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(LOSS_DIR)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(MODEL_DIR)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# save teh model every n epochs\n",
    "SAVE_RATE = 500\n",
    "# save teh output and loss every n epochs\n",
    "SAMPLE_RATE = 50\n",
    "# sqrt of number of images to sample\n",
    "SAMPLE_NUM = 6\n",
    "\n",
    "# epochs to train for\n",
    "EPOCHS = 10000\n",
    "# batch size of images\n",
    "BATCH_SIZE = 128\n",
    "# number of batches to train discriminator per epoch\n",
    "DISCRIM_ITER = 5\n",
    "# WGAN-recommended weight clipping value\n",
    "WEIGHT_CLIP = 0.01\n",
    "# dimensions of the input noise vector\n",
    "LATENT_DIM = 100\n",
    "# optimizer to use for each model\n",
    "OPTIMIZER = RMSprop(lr=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    "\n",
    "def load_data():\n",
    "    # load data\n",
    "    raw_images = glob.glob(DATA_DIR + '*' + IMG_EXT)\n",
    "    # read data\n",
    "    images = np.array([np.array(Image.open(image)) for image in raw_images])\n",
    "    # shuffle data\n",
    "    np.random.shuffle(images)\n",
    "    # rearrange data\n",
    "    images = images.reshape(images.shape[0], 104, 88, 1)\n",
    "    # normalize data [-1, 1]\n",
    "    images = (images.astype(np.float) - 127.5)/127.5\n",
    "    \n",
    "    return images\n",
    "\n",
    "def plot_loss(name, gen_loss, disc_loss, d_r_loss, d_f_loss):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(gen_loss, label='Gen. Loss')\n",
    "    plt.plot(disc_loss, label='Discrim. Total Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(LOSS_DIR + name + '_total_loss_plot' + IMG_EXT)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(gen_loss, label='Gen. Loss')\n",
    "    plt.plot(d_r_loss, label='Discrim. Real Loss')\n",
    "    plt.plot(d_f_loss, label='Discrim. Fake Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(LOSS_DIR + name + '_real_fake_loss_plot' + IMG_EXT)\n",
    "    plt.close()\n",
    "    \n",
    "def save_output(epoch, model):\n",
    "    # generate 25 images\n",
    "    images = model.generator.predict(np.random.normal(0, 1, (SAMPLE_NUM**2, LATENT_DIM)))\n",
    "    # normalize images [0,1]\n",
    "    images = 0.5 * images + 0.5\n",
    "    # make a square plot\n",
    "    fig, axs = plt.subplots(SAMPLE_NUM, SAMPLE_NUM, figsize=(10, 10))\n",
    "    img_idx = 0\n",
    "    for y in range(SAMPLE_NUM):\n",
    "        for x in range(SAMPLE_NUM):\n",
    "            axs[x,y].imshow(images[img_idx, :,:,0], cmap='gray')\n",
    "            axs[x,y].axis('off')\n",
    "            img_idx += 1\n",
    "    # pad the output names to make things cleaner\n",
    "    fig.savefig(IMAGE_DIR + model.name + '_sample_' + str(epoch).zfill(5) + IMG_EXT)\n",
    "    plt.close()\n",
    "    \n",
    "def save_loss(name, g_loss, d_loss, d_r_loss, d_f_loss):\n",
    "    np.save(LOSS_DIR + name + '_gen_loss', g_loss)\n",
    "    np.save(LOSS_DIR + name + '_total_discrim_loss', d_loss)\n",
    "    np.save(LOSS_DIR + name + '_discrim_fake_loss', d_f_loss)\n",
    "    np.save(LOSS_DIR + name + '_discrim_real_loss', d_r_loss)\n",
    "    \n",
    "def save_model(epoch, model):\n",
    "    model.discriminator.save(MODEL_DIR + model.name + \n",
    "                             '_discrim_' + str(epoch).zfill(5) + '.h5')\n",
    "    model.combined.save(MODEL_DIR + model.name + \n",
    "                        '_combined_' + str(epoch).zfill(5) + '.h5')\n",
    "    \n",
    "def train(model, training_data):\n",
    "\n",
    "        # create labels for GAN\n",
    "        if model.wasserstein == False:\n",
    "            r_labels = np.ones((BATCH_SIZE, 1))\n",
    "            f_labels = np.zeros((BATCH_SIZE, 1))\n",
    "        # create labels for WGAN\n",
    "        else:\n",
    "            r_labels = np.ones((BATCH_SIZE, 1))\n",
    "            f_labels = -np.ones((BATCH_SIZE, 1))\n",
    "\n",
    "        # lists to store the losses\n",
    "        all_d_r_loss = []\n",
    "        all_d_f_loss = []\n",
    "        all_g_loss = []\n",
    "        all_d_loss = []\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            \n",
    "            for _ in tqdm(range(DISCRIM_ITER)):\n",
    "\n",
    "                # sample a (pseudo-)random batch of images\n",
    "                r_imgs = training_data[np.random.randint(\n",
    "                    0, training_data.shape[0], BATCH_SIZE) ]\n",
    "                \n",
    "                # generate batch of images\n",
    "                noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "                f_imgs = model.generator.predict(noise)\n",
    "\n",
    "                # train discrim on real and generated seperately\n",
    "                d_r_loss = model.discriminator.train_on_batch(r_imgs, r_labels) \n",
    "                d_f_loss = model.discriminator.train_on_batch(f_imgs, f_labels)\n",
    "                d_loss = 0.5 * np.add(d_f_loss, d_r_loss)\n",
    "                \n",
    "                # Clip critic weights\n",
    "                for l in model.discriminator.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -WEIGHT_CLIP, WEIGHT_CLIP) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "            # train the generator (via combined model)\n",
    "            noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
    "            g_loss = model.combined.train_on_batch(noise, r_labels) \n",
    "\n",
    "                            \n",
    "            # clear the output every 10 iterations\n",
    "            if epoch % 10 == 0:\n",
    "                clear_output()\n",
    "        \n",
    "            all_d_r_loss.append(d_r_loss)\n",
    "            all_d_f_loss.append(d_f_loss)\n",
    "            all_g_loss.append(g_loss)\n",
    "            all_d_loss.append(d_loss)\n",
    "            print(\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
    "\n",
    "            # log at the sampling interval\n",
    "            if epoch % SAMPLE_RATE == 0 or epoch == EPOCHS - 1:\n",
    "                save_output(epoch, model)\n",
    "                save_loss(model.name, np.array(all_g_loss), np.array(all_d_loss), \n",
    "                          np.array(all_d_r_loss), np.array(all_d_f_loss))\n",
    "                plot_loss(model.name, all_g_loss, all_d_loss, all_d_r_loss, all_d_f_loss)\n",
    "                \n",
    "            # save at the saving interval\n",
    "            if epoch % SAVE_RATE == 0 or epoch == EPOCHS - 1:\n",
    "                save_model(epoch, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the class for the models, toggleable to make WGAN or GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, wasserstein=False):\n",
    "        # check if WGAN\n",
    "        if wasserstein == True:\n",
    "            loss = wasserstein_loss\n",
    "            self.name = 'WGAN'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            self.name = 'GAN'\n",
    "        # set flag since faster than string comparison\n",
    "        self.wasserstein = wasserstein\n",
    "        \n",
    "        # get and compile the discriminator\n",
    "        self.discriminator = self.get_discriminator()\n",
    "        self.discriminator.compile(loss=loss, optimizer=OPTIMIZER)\n",
    "        # set not trainable for combined version (compiled is still trainable)\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # get the generator but don't compile it\n",
    "        self.generator = self.get_generator()\n",
    "        \n",
    "        # build all the necessary in's and out's\n",
    "        g_in = Input(shape=(LATENT_DIM, ))\n",
    "        g_out = self.generator(g_in)\n",
    "        d_out = self.discriminator(g_out)\n",
    "        \n",
    "        # construct and compile the actual combined model\n",
    "        self.combined = Model(g_in, d_out)\n",
    "        self.combined.compile(loss=loss, optimizer=OPTIMIZER)\n",
    "        \n",
    "    def get_discriminator(self):\n",
    "        discrim = Sequential()\n",
    "    \n",
    "        discrim.add(Conv2D(64, kernel_size=(12, 10), strides=1, padding='same', \n",
    "                           input_shape=IMG_SHAPE))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.2))\n",
    "        \n",
    "        discrim.add(Conv2D(64, kernel_size=(4, 4), strides=1, padding='same'))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.2))\n",
    "        \n",
    "        discrim.add(Conv2D(64, kernel_size=(6, 5), strides=2, padding='same'))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.2))\n",
    "    \n",
    "        discrim.add(Conv2D(128, kernel_size=(6, 5), strides=2, padding='same'))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.3))\n",
    "        \n",
    "        discrim.add(Conv2D(256, kernel_size=(6, 5), strides=2, padding='same'))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.2))\n",
    "    \n",
    "        discrim.add(Flatten())\n",
    "        discrim.add(Dense(18))\n",
    "        discrim.add(Activation('selu'))\n",
    "        discrim.add(Dropout(0.2))\n",
    "        discrim.add(Dense(1))\n",
    "        \n",
    "        # add sigmoid to create a GAN instead of a WGAN\n",
    "        if self.wasserstein == False:\n",
    "            discrim.add(Activation('sigmoid'))\n",
    "        \n",
    "        d_in = Input(shape=IMG_SHAPE)\n",
    "        d_out = discrim(d_in)\n",
    "        \n",
    "        discrim.summary()\n",
    "\n",
    "        return Model(d_in, d_out)\n",
    "        \n",
    "    def get_generator(self):\n",
    "        gen = Sequential()\n",
    "\n",
    "        gen.add(Dense(128 * 13 * 11, input_dim=LATENT_DIM))\n",
    "        gen.add(Activation('selu'))\n",
    "        gen.add(Reshape((13, 11, 128)))\n",
    "    \n",
    "        gen.add(UpSampling2D())\n",
    "        gen.add(Conv2D(128, (6, 5), strides=1, padding='same'))\n",
    "        gen.add(Activation('selu'))\n",
    "\n",
    "        gen.add(UpSampling2D())\n",
    "        gen.add(Conv2D(64, (6, 5), strides=1, padding='same'))\n",
    "        gen.add(Activation('selu'))\n",
    "    \n",
    "        gen.add(UpSampling2D())\n",
    "        gen.add(Conv2D(32, (6, 5), strides=1, padding='same'))\n",
    "        gen.add(Activation('selu'))\n",
    "        \n",
    "        gen.add(UpSampling2D())\n",
    "        gen.add(Conv2D(32, (6, 5), strides=2, padding='same'))\n",
    "        gen.add(Activation('selu'))\n",
    "        \n",
    "        gen.add(Conv2D(1, kernel_size=(6, 5), strides=1, padding='same'))\n",
    "        gen.add(Activation('tanh'))\n",
    "    \n",
    "        g_in = Input(shape=(LATENT_DIM,))\n",
    "        g_out = gen(g_in)\n",
    "        \n",
    "        gen.summary()\n",
    "    \n",
    "        return Model(g_in, g_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wgan = GAN(wasserstein=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(wgan, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(wasserstein=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(gan, training_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
